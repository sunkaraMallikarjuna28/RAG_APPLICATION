{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import PyPDF2\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import google.generativeai as genai\n",
    "import pymongo\n",
    "from langchain import hub\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from docx import Document\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRAGApp:\n",
    "    def __init__(self):\n",
    "        print(\"🚀 Starting Simple RAG Application...\")\n",
    "        \n",
    "        # Setup Google AI\n",
    "        self.google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "        genai.configure(api_key=self.google_api_key)\n",
    "        \n",
    "        # Setup MongoDB\n",
    "        self.mongo_uri = os.getenv(\"MONGODB_URI\")\n",
    "        self.client = pymongo.MongoClient(self.mongo_uri)\n",
    "        self.db = self.client[\"rag_database\"]\n",
    "        self.collection = self.db[\"document_chunks\"]\n",
    "        \n",
    "        # Setup embeddings for semantic chunking\n",
    "        self.embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "        \n",
    "        # Setup semantic chunker\n",
    "        self.text_splitter = SemanticChunker(embeddings=self.embeddings)\n",
    "        \n",
    "        # Setup Gemini LLM\n",
    "        self.model = ChatGoogleGenerativeAI(\n",
    "            model=\"gemini-1.5-flash\",\n",
    "            google_api_key=self.google_api_key\n",
    "        )\n",
    "        \n",
    "        # Setup RAG prompt\n",
    "        self.prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "        \n",
    "        print(\"✅ RAG Application initialized!\")\n",
    "\n",
    "    def extract_pdf_text(self, pdf_path):\n",
    "        \"\"\"Step 1: Extract text from PDF\"\"\"\n",
    "        print(f\"📄 Reading PDF: {pdf_path}\")\n",
    "        \n",
    "        try:\n",
    "            with open(pdf_path, 'rb') as file:\n",
    "                pdf_reader = PyPDF2.PdfReader(file)\n",
    "                text = \"\"\n",
    "                \n",
    "                for page_num, page in enumerate(pdf_reader.pages):\n",
    "                    page_text = page.extract_text()\n",
    "                    text += page_text\n",
    "                    print(f\"   ✅ Page {page_num + 1} processed\")\n",
    "                \n",
    "                print(f\"📊 Total text extracted: {len(text)} characters\")\n",
    "                return text\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error reading PDF: {e}\")\n",
    "            return None\n",
    "    def create_semantic_chunks(self, text):\n",
    "        \"\"\"Step 2: Create semantic chunks\"\"\"\n",
    "        print(\"🧠 Creating semantic chunks...\")\n",
    "        \n",
    "        try:\n",
    "            chunks = self.text_splitter.split_text(text)\n",
    "            print(f\"✅ Created {len(chunks)} semantic chunks\")\n",
    "            \n",
    "            # Show sample chunks\n",
    "            for i, chunk in enumerate(chunks[:2]):\n",
    "                print(f\"   Sample Chunk {i+1}: {chunk[:100]}...\")\n",
    "            \n",
    "            return chunks\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error creating chunks: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def process_pdf_and_query(self, pdf_path, query):\n",
    "        \"\"\"Complete RAG pipeline\"\"\"\n",
    "        print(\"🎯 Starting complete RAG pipeline...\")\n",
    "        \n",
    "        # Step 1: Extract text from PDF\n",
    "        text = self.extract_pdf_text(pdf_path)\n",
    "        if not text:\n",
    "            return\n",
    "        \n",
    "        # Step 2: Create semantic chunks\n",
    "        chunks = self.create_semantic_chunks(text)\n",
    "        if not chunks:\n",
    "            return\n",
    "        \n",
    "        # # Step 3: Generate embeddings\n",
    "        # chunk_embeddings = self.generate_embeddings(chunks)\n",
    "        # if not chunk_embeddings:\n",
    "        #     return\n",
    "        \n",
    "        # # Step 4: Store in MongoDB\n",
    "        # self.store_in_mongodb(chunk_embeddings)\n",
    "        \n",
    "        # # Step 5: Generate answer\n",
    "        # answer = self.generate_answer(query)\n",
    "        \n",
    "        # # Step 6: Save to DOCX\n",
    "        # self.save_to_docx(query, answer)\n",
    "        \n",
    "        # print(\"\\n🎉 RAG Pipeline Complete!\")\n",
    "        # print(f\"📝 Question: {query}\")\n",
    "        # print(f\"💡 Answer: {answer[:200]}...\")\n",
    "        \n",
    "        # return answer        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Simple RAG Application...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AI\\assginment_env\\ragenv\\Lib\\site-packages\\langchain\\hub.py:86: DeprecationWarning: The `langchainhub sdk` is deprecated.\n",
      "Please use the `langsmith sdk` instead:\n",
      "  pip install langsmith\n",
      "Use the `pull_prompt` method.\n",
      "  res_dict = client.pull_repo(owner_repo_commit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RAG Application initialized!\n",
      "🎯 Starting complete RAG pipeline...\n",
      "📄 Reading PDF: d:\\AI\\assginment_env\\data\\pythonai.pdf\n",
      "   ✅ Page 1 processed\n",
      "   ✅ Page 2 processed\n",
      "   ✅ Page 3 processed\n",
      "   ✅ Page 4 processed\n",
      "   ✅ Page 5 processed\n",
      "   ✅ Page 6 processed\n",
      "   ✅ Page 7 processed\n",
      "   ✅ Page 8 processed\n",
      "   ✅ Page 9 processed\n",
      "   ✅ Page 10 processed\n",
      "   ✅ Page 11 processed\n",
      "   ✅ Page 12 processed\n",
      "   ✅ Page 13 processed\n",
      "   ✅ Page 14 processed\n",
      "   ✅ Page 15 processed\n",
      "   ✅ Page 16 processed\n",
      "   ✅ Page 17 processed\n",
      "   ✅ Page 18 processed\n",
      "   ✅ Page 19 processed\n",
      "   ✅ Page 20 processed\n",
      "   ✅ Page 21 processed\n",
      "   ✅ Page 22 processed\n",
      "   ✅ Page 23 processed\n",
      "   ✅ Page 24 processed\n",
      "   ✅ Page 25 processed\n",
      "   ✅ Page 26 processed\n",
      "   ✅ Page 27 processed\n",
      "   ✅ Page 28 processed\n",
      "   ✅ Page 29 processed\n",
      "   ✅ Page 30 processed\n",
      "   ✅ Page 31 processed\n",
      "   ✅ Page 32 processed\n",
      "   ✅ Page 33 processed\n",
      "   ✅ Page 34 processed\n",
      "   ✅ Page 35 processed\n",
      "   ✅ Page 36 processed\n",
      "   ✅ Page 37 processed\n",
      "   ✅ Page 38 processed\n",
      "   ✅ Page 39 processed\n",
      "   ✅ Page 40 processed\n",
      "   ✅ Page 41 processed\n",
      "   ✅ Page 42 processed\n",
      "   ✅ Page 43 processed\n",
      "   ✅ Page 44 processed\n",
      "   ✅ Page 45 processed\n",
      "   ✅ Page 46 processed\n",
      "   ✅ Page 47 processed\n",
      "   ✅ Page 48 processed\n",
      "   ✅ Page 49 processed\n",
      "   ✅ Page 50 processed\n",
      "   ✅ Page 51 processed\n",
      "   ✅ Page 52 processed\n",
      "   ✅ Page 53 processed\n",
      "   ✅ Page 54 processed\n",
      "   ✅ Page 55 processed\n",
      "   ✅ Page 56 processed\n",
      "   ✅ Page 57 processed\n",
      "   ✅ Page 58 processed\n",
      "   ✅ Page 59 processed\n",
      "   ✅ Page 60 processed\n",
      "   ✅ Page 61 processed\n",
      "   ✅ Page 62 processed\n",
      "   ✅ Page 63 processed\n",
      "   ✅ Page 64 processed\n",
      "   ✅ Page 65 processed\n",
      "   ✅ Page 66 processed\n",
      "   ✅ Page 67 processed\n",
      "   ✅ Page 68 processed\n",
      "   ✅ Page 69 processed\n",
      "   ✅ Page 70 processed\n",
      "   ✅ Page 71 processed\n",
      "   ✅ Page 72 processed\n",
      "   ✅ Page 73 processed\n",
      "   ✅ Page 74 processed\n",
      "   ✅ Page 75 processed\n",
      "   ✅ Page 76 processed\n",
      "   ✅ Page 77 processed\n",
      "   ✅ Page 78 processed\n",
      "   ✅ Page 79 processed\n",
      "   ✅ Page 80 processed\n",
      "   ✅ Page 81 processed\n",
      "   ✅ Page 82 processed\n",
      "   ✅ Page 83 processed\n",
      "   ✅ Page 84 processed\n",
      "   ✅ Page 85 processed\n",
      "   ✅ Page 86 processed\n",
      "   ✅ Page 87 processed\n",
      "   ✅ Page 88 processed\n",
      "   ✅ Page 89 processed\n",
      "   ✅ Page 90 processed\n",
      "   ✅ Page 91 processed\n",
      "   ✅ Page 92 processed\n",
      "   ✅ Page 93 processed\n",
      "   ✅ Page 94 processed\n",
      "   ✅ Page 95 processed\n",
      "   ✅ Page 96 processed\n",
      "   ✅ Page 97 processed\n",
      "   ✅ Page 98 processed\n",
      "   ✅ Page 99 processed\n",
      "   ✅ Page 100 processed\n",
      "   ✅ Page 101 processed\n",
      "   ✅ Page 102 processed\n",
      "   ✅ Page 103 processed\n",
      "   ✅ Page 104 processed\n",
      "   ✅ Page 105 processed\n",
      "   ✅ Page 106 processed\n",
      "   ✅ Page 107 processed\n",
      "   ✅ Page 108 processed\n",
      "   ✅ Page 109 processed\n",
      "   ✅ Page 110 processed\n",
      "   ✅ Page 111 processed\n",
      "   ✅ Page 112 processed\n",
      "   ✅ Page 113 processed\n",
      "   ✅ Page 114 processed\n",
      "   ✅ Page 115 processed\n",
      "   ✅ Page 116 processed\n",
      "   ✅ Page 117 processed\n",
      "   ✅ Page 118 processed\n",
      "   ✅ Page 119 processed\n",
      "   ✅ Page 120 processed\n",
      "   ✅ Page 121 processed\n",
      "   ✅ Page 122 processed\n",
      "   ✅ Page 123 processed\n",
      "   ✅ Page 124 processed\n",
      "   ✅ Page 125 processed\n",
      "   ✅ Page 126 processed\n",
      "   ✅ Page 127 processed\n",
      "   ✅ Page 128 processed\n",
      "   ✅ Page 129 processed\n",
      "   ✅ Page 130 processed\n",
      "   ✅ Page 131 processed\n",
      "   ✅ Page 132 processed\n",
      "   ✅ Page 133 processed\n",
      "   ✅ Page 134 processed\n",
      "   ✅ Page 135 processed\n",
      "   ✅ Page 136 processed\n",
      "   ✅ Page 137 processed\n",
      "   ✅ Page 138 processed\n",
      "   ✅ Page 139 processed\n",
      "   ✅ Page 140 processed\n",
      "   ✅ Page 141 processed\n",
      "   ✅ Page 142 processed\n",
      "   ✅ Page 143 processed\n",
      "   ✅ Page 144 processed\n",
      "   ✅ Page 145 processed\n",
      "   ✅ Page 146 processed\n",
      "   ✅ Page 147 processed\n",
      "   ✅ Page 148 processed\n",
      "   ✅ Page 149 processed\n",
      "   ✅ Page 150 processed\n",
      "   ✅ Page 151 processed\n",
      "   ✅ Page 152 processed\n",
      "   ✅ Page 153 processed\n",
      "   ✅ Page 154 processed\n",
      "   ✅ Page 155 processed\n",
      "   ✅ Page 156 processed\n",
      "   ✅ Page 157 processed\n",
      "   ✅ Page 158 processed\n",
      "   ✅ Page 159 processed\n",
      "   ✅ Page 160 processed\n",
      "   ✅ Page 161 processed\n",
      "   ✅ Page 162 processed\n",
      "   ✅ Page 163 processed\n",
      "   ✅ Page 164 processed\n",
      "   ✅ Page 165 processed\n",
      "   ✅ Page 166 processed\n",
      "   ✅ Page 167 processed\n",
      "   ✅ Page 168 processed\n",
      "   ✅ Page 169 processed\n",
      "   ✅ Page 170 processed\n",
      "   ✅ Page 171 processed\n",
      "   ✅ Page 172 processed\n",
      "   ✅ Page 173 processed\n",
      "   ✅ Page 174 processed\n",
      "   ✅ Page 175 processed\n",
      "   ✅ Page 176 processed\n",
      "   ✅ Page 177 processed\n",
      "   ✅ Page 178 processed\n",
      "   ✅ Page 179 processed\n",
      "   ✅ Page 180 processed\n",
      "   ✅ Page 181 processed\n",
      "   ✅ Page 182 processed\n",
      "   ✅ Page 183 processed\n",
      "   ✅ Page 184 processed\n",
      "   ✅ Page 185 processed\n",
      "   ✅ Page 186 processed\n",
      "   ✅ Page 187 processed\n",
      "   ✅ Page 188 processed\n",
      "   ✅ Page 189 processed\n",
      "   ✅ Page 190 processed\n",
      "   ✅ Page 191 processed\n",
      "   ✅ Page 192 processed\n",
      "   ✅ Page 193 processed\n",
      "   ✅ Page 194 processed\n",
      "   ✅ Page 195 processed\n",
      "   ✅ Page 196 processed\n",
      "   ✅ Page 197 processed\n",
      "   ✅ Page 198 processed\n",
      "   ✅ Page 199 processed\n",
      "   ✅ Page 200 processed\n",
      "   ✅ Page 201 processed\n",
      "   ✅ Page 202 processed\n",
      "   ✅ Page 203 processed\n",
      "   ✅ Page 204 processed\n",
      "   ✅ Page 205 processed\n",
      "   ✅ Page 206 processed\n",
      "   ✅ Page 207 processed\n",
      "   ✅ Page 208 processed\n",
      "   ✅ Page 209 processed\n",
      "   ✅ Page 210 processed\n",
      "   ✅ Page 211 processed\n",
      "   ✅ Page 212 processed\n",
      "   ✅ Page 213 processed\n",
      "   ✅ Page 214 processed\n",
      "   ✅ Page 215 processed\n",
      "   ✅ Page 216 processed\n",
      "   ✅ Page 217 processed\n",
      "   ✅ Page 218 processed\n",
      "   ✅ Page 219 processed\n",
      "   ✅ Page 220 processed\n",
      "   ✅ Page 221 processed\n",
      "   ✅ Page 222 processed\n",
      "   ✅ Page 223 processed\n",
      "   ✅ Page 224 processed\n",
      "   ✅ Page 225 processed\n",
      "   ✅ Page 226 processed\n",
      "   ✅ Page 227 processed\n",
      "   ✅ Page 228 processed\n",
      "   ✅ Page 229 processed\n",
      "   ✅ Page 230 processed\n",
      "   ✅ Page 231 processed\n",
      "   ✅ Page 232 processed\n",
      "   ✅ Page 233 processed\n",
      "   ✅ Page 234 processed\n",
      "   ✅ Page 235 processed\n",
      "   ✅ Page 236 processed\n",
      "   ✅ Page 237 processed\n",
      "   ✅ Page 238 processed\n",
      "   ✅ Page 239 processed\n",
      "   ✅ Page 240 processed\n",
      "   ✅ Page 241 processed\n",
      "   ✅ Page 242 processed\n",
      "   ✅ Page 243 processed\n",
      "   ✅ Page 244 processed\n",
      "   ✅ Page 245 processed\n",
      "   ✅ Page 246 processed\n",
      "   ✅ Page 247 processed\n",
      "   ✅ Page 248 processed\n",
      "   ✅ Page 249 processed\n",
      "   ✅ Page 250 processed\n",
      "   ✅ Page 251 processed\n",
      "   ✅ Page 252 processed\n",
      "   ✅ Page 253 processed\n",
      "   ✅ Page 254 processed\n",
      "   ✅ Page 255 processed\n",
      "   ✅ Page 256 processed\n",
      "   ✅ Page 257 processed\n",
      "   ✅ Page 258 processed\n",
      "   ✅ Page 259 processed\n",
      "   ✅ Page 260 processed\n",
      "   ✅ Page 261 processed\n",
      "   ✅ Page 262 processed\n",
      "   ✅ Page 263 processed\n",
      "   ✅ Page 264 processed\n",
      "   ✅ Page 265 processed\n",
      "   ✅ Page 266 processed\n",
      "   ✅ Page 267 processed\n",
      "   ✅ Page 268 processed\n",
      "   ✅ Page 269 processed\n",
      "   ✅ Page 270 processed\n",
      "   ✅ Page 271 processed\n",
      "   ✅ Page 272 processed\n",
      "   ✅ Page 273 processed\n",
      "   ✅ Page 274 processed\n",
      "   ✅ Page 275 processed\n",
      "   ✅ Page 276 processed\n",
      "   ✅ Page 277 processed\n",
      "   ✅ Page 278 processed\n",
      "   ✅ Page 279 processed\n",
      "   ✅ Page 280 processed\n",
      "   ✅ Page 281 processed\n",
      "   ✅ Page 282 processed\n",
      "   ✅ Page 283 processed\n",
      "   ✅ Page 284 processed\n",
      "   ✅ Page 285 processed\n",
      "   ✅ Page 286 processed\n",
      "   ✅ Page 287 processed\n",
      "   ✅ Page 288 processed\n",
      "   ✅ Page 289 processed\n",
      "   ✅ Page 290 processed\n",
      "   ✅ Page 291 processed\n",
      "   ✅ Page 292 processed\n",
      "   ✅ Page 293 processed\n",
      "   ✅ Page 294 processed\n",
      "   ✅ Page 295 processed\n",
      "📊 Total text extracted: 573538 characters\n"
     ]
    }
   ],
   "source": [
    "# Initialize RAG app\n",
    "rag_app = SimpleRAGApp()\n",
    "\n",
    "\n",
    "# # Get current directory\n",
    "# current_dir = Path.cwd()\n",
    "# print(f\"Current directory: {current_dir}\")\n",
    "\n",
    "# pdf_path = os.path.join(current_dir ,\"data\", \"pyhtonapplications.pdf\")\n",
    "# output_path = os.path.join(current_dir ,\"outputs\", \"result.docx\")\n",
    "# Process your PDF\n",
    "\n",
    "query = \"What is the main topic of this document?\"  # Change this to your question\n",
    "    \n",
    "# Run complete pipeline\n",
    "answer = rag_app.process_pdf_and_query(r\"d:\\AI\\assginment_env\\data\\pythonai.pdf\", query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
